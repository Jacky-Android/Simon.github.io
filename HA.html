<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<!-- iOS Safari -->
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
<!-- Chrome, Firefox OS and Opera Status Bar Color -->
<meta name="theme-color" content="#FFFFFF">
<link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css">
<link rel="stylesheet" type="text/css"
  href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.19.0/themes/prism.min.css">
<link rel="stylesheet" type="text/css" href="css/SourceSansPro.css">
<link rel="stylesheet" type="text/css" href="css/theme.css">
<link rel="stylesheet" type="text/css" href="css/notablog.css">
<!-- Favicon -->

  <link rel="shortcut icon" href="https://avatars.githubusercontent.com/u/55181594?v=4">

<style>
  :root {
    font-size: 20px;
  }
</style>
  <title>HAFormer复现&nbsp;|&nbsp;Simon’s Blogs</title>
  <meta property="og:type" content="blog">
  <meta property="og:title" content="HAFormer复现">
  
  
    <meta property="og:image" content="data:image/svg+xml,&lt;svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22&gt;&lt;text text-anchor=%22middle%22 dominant-baseline=%22middle%22 x=%2250%22 y=%2255%22 font-size=%2280%22&gt;😶&lt;/text&gt;&lt;/svg&gt;">
  
  <style>
    .DateTagBar {
      margin-top: 1.0rem;
    }
  </style>
</head>

<body>
  <nav class="Navbar">
  <a href="index.html">
    <div class="Navbar__Btn">
      
        <span><img class="inline-img-icon" src="https://avatars.githubusercontent.com/u/55181594?v=4"></span>&nbsp;
      
      <span>Home</span>
    </div>
  </a>
  
    
  
    
      <span class="Navbar__Delim">&centerdot;</span>
      <a href="road.html">
        <div class="Navbar__Btn">
          
            <span><img class="inline-img-icon" src="data:image/svg+xml,&lt;svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22&gt;&lt;text text-anchor=%22middle%22 dominant-baseline=%22middle%22 x=%2250%22 y=%2255%22 font-size=%2280%22&gt;🤑&lt;/text&gt;&lt;/svg&gt;"></span>&nbsp;
          
          <span>2024年深度学习学习路线</span>
        </div>
      </a>
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
      <span class="Navbar__Delim">&centerdot;</span>
      <a href="about.html">
        <div class="Navbar__Btn">
          
            <span><img class="inline-img-icon" src="data:image/svg+xml,&lt;svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22&gt;&lt;text text-anchor=%22middle%22 dominant-baseline=%22middle%22 x=%2250%22 y=%2255%22 font-size=%2280%22&gt;😀&lt;/text&gt;&lt;/svg&gt;"></span>&nbsp;
          
          <span>About me</span>
        </div>
      </a>
    
  
    
  
    
      <span class="Navbar__Delim">&centerdot;</span>
      <a href="12.html">
        <div class="Navbar__Btn">
          
            <span><img class="inline-img-icon" src="data:image/svg+xml,&lt;svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22&gt;&lt;text text-anchor=%22middle%22 dominant-baseline=%22middle%22 x=%2250%22 y=%2255%22 font-size=%2280%22&gt;🤏&lt;/text&gt;&lt;/svg&gt;"></span>&nbsp;
          
          <span>训练神经网络的技巧</span>
        </div>
      </a>
    
  
    
      <span class="Navbar__Delim">&centerdot;</span>
      <a href="HA.html">
        <div class="Navbar__Btn">
          
            <span><img class="inline-img-icon" src="data:image/svg+xml,&lt;svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22&gt;&lt;text text-anchor=%22middle%22 dominant-baseline=%22middle%22 x=%2250%22 y=%2255%22 font-size=%2280%22&gt;😶&lt;/text&gt;&lt;/svg&gt;"></span>&nbsp;
          
          <span>HAFormer复现</span>
        </div>
      </a>
    
  
    
      <span class="Navbar__Delim">&centerdot;</span>
      <a href="ma.html">
        <div class="Navbar__Btn">
          
          <span>‣ </span>
        </div>
      </a>
    
  
</nav>
  <header class="Header">
    
    <div class="Header__Spacer Header__Spacer--NoCover">
    </div>
    
      <div class="Header__Icon">
        <span><img class="inline-img-icon" src="data:image/svg+xml,&lt;svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22&gt;&lt;text text-anchor=%22middle%22 dominant-baseline=%22middle%22 x=%2250%22 y=%2255%22 font-size=%2280%22&gt;😶&lt;/text&gt;&lt;/svg&gt;"></span>
      </div>
    
    <h1 class="Header__Title">HAFormer复现</h1>
    
  </header>
  <article id="https://www.notion.so/b38bb7cc094e42df892f5fc60de08a5b" class="PageRoot"><div id="https://www.notion.so/91d7acba26114ccd89fcd8bc5c71888a" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">HAFormer_recurrent</strong></span></span></p></div><div></div><div id="https://www.notion.so/10a76526d1cc8022b818cb0219b4fbe1" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">在作者发布之前尝试复现，坐等作者发布🤓🤓🤓</span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://github.com/XU-GITHUB-curry/HAFormer">HAFormer</a></span></span></p></div><div id="https://www.notion.so/e18655de38f04bb29bccdefddc980a6a" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">Paper: HAFormer: Unleashing the Power of Hierarchy-Aware Features for Lightweight Semantic Segmentation</span></span></p></div><div id="https://www.notion.so/e415b5c1ca864ebc9a079c14efb6e8d1" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">[1] G. Xu, W. Jia, T. Wu, L. Chen, and G. Gao, “HAFormer: Unleashing the Power of Hierarchy-Aware Features for Lightweight Semantic Segmentation,” IEEE Trans. on Image Process., pp. 1–1, 2024, doi: 10.1109/TIP.2024.3425048.</span></span></p></div><div id="https://www.notion.so/10a76526d1cc80eb8aa3fa120d22e485" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">模型结构</strong></span></span></p></div><pre id="https://www.notion.so/10a76526d1cc8092bf60ccdeb8f44a0d" class="Code"><code><span class="SemanticStringArray"><span class="SemanticString"><span>==============================================================================================================
Layer (type:depth-idx)                                       Output Shape              Param #
==============================================================================================================
HAPEFormer                                                   [1, 6, 1024, 1024]        147,648
├─FeatureListNet: 1-1                                        [1, 48, 256, 256]         --
│    └─ConvNormAct: 2-1                                      [1, 24, 512, 512]         --
│    │    └─Dropout: 3-1                                     [1, 3, 1024, 1024]        --
│    │    └─Conv2d: 3-2                                      [1, 24, 512, 512]         648
│    │    └─BatchNorm2d: 3-3                                 [1, 24, 512, 512]         48
│    │    └─Hardswish: 3-4                                   [1, 24, 512, 512]         --
│    └─ResidualBlock: 2-2                                    [1, 24, 512, 512]         --
│    │    └─Identity: 3-5                                    [1, 24, 512, 512]         --
│    │    └─DSConv: 3-6                                      [1, 24, 512, 512]         888
│    │    └─Identity: 3-7                                    [1, 24, 512, 512]         --
│    └─EfficientVitStage: 2-3                                [1, 48, 256, 256]         --
│    │    └─Sequential: 3-8                                  [1, 48, 256, 256]         50,304
│    └─EfficientVitStage: 2-4                                [1, 96, 128, 128]         --
│    │    └─Sequential: 3-9                                  [1, 96, 128, 128]         267,072
│    └─EfficientVitStage: 2-5                                [1, 192, 64, 64]          --
│    │    └─Sequential: 3-10                                 [1, 192, 64, 64]          2,200,320
│    └─EfficientVitStage: 2-6                                [1, 384, 32, 32]          --
│    │    └─Sequential: 3-11                                 [1, 384, 32, 32]          12,457,728
├─Downsample: 1-2                                            [1, 32, 512, 512]         --
│    └─Conv2d: 2-7                                           [1, 32, 512, 512]         896
├─SeparableConvBN: 1-3                                       [1, 32, 512, 512]         --
│    └─Conv2d: 2-8                                           [1, 32, 512, 512]         288
│    └─BatchNorm2d: 2-9                                      [1, 32, 512, 512]         64
│    └─Conv2d: 2-10                                          [1, 32, 512, 512]         1,024
├─Downsample: 1-4                                            [1, 32, 256, 256]         --
│    └─Conv2d: 2-11                                          [1, 32, 256, 256]         9,248
├─ModuleList: 1-13                                           --                        (recursive)
│    └─Sequential: 2-12                                      [1, 32, 256, 256]         --
│    │    └─HAPEBlock: 3-12                                  [1, 32, 256, 256]         3,856
│    │    └─HAPEBlock: 3-13                                  [1, 32, 256, 256]         3,856
│    │    └─HAPEBlock: 3-14                                  [1, 32, 256, 256]         3,856
├─Downsample: 1-6                                            [1, 64, 128, 128]         --
│    └─Conv2d: 2-13                                          [1, 64, 128, 128]         18,496
├─ModuleList: 1-13                                           --                        (recursive)
│    └─Sequential: 2-14                                      [1, 64, 128, 128]         --
│    │    └─HAPEBlock: 3-15                                  [1, 64, 128, 128]         6,992
│    │    └─HAPEBlock: 3-16                                  [1, 64, 128, 128]         6,992
│    │    └─HAPEBlock: 3-17                                  [1, 64, 128, 128]         3,912
│    │    └─HAPEBlock: 3-18                                  [1, 64, 128, 128]         3,912
│    │    └─HAPEBlock: 3-19                                  [1, 64, 128, 128]         2,372
│    │    └─HAPEBlock: 3-20                                  [1, 64, 128, 128]         2,372
├─Conv2d: 1-8                                                [1, 128, 128, 128]        8,192
├─ModuleList: 1-13                                           --                        (recursive)
│    └─Sequential: 2-15                                      [1, 128, 128, 128]        --
│    │    └─HAPEBlock: 3-21                                  [1, 128, 128, 128]        26,272
│    │    └─HAPEBlock: 3-22                                  [1, 128, 128, 128]        26,272
│    │    └─HAPEBlock: 3-23                                  [1, 128, 128, 128]        13,968
│    │    └─HAPEBlock: 3-24                                  [1, 128, 128, 128]        13,968
│    │    └─HAPEBlock: 3-25                                  [1, 128, 128, 128]        7,816
│    │    └─HAPEBlock: 3-26                                  [1, 128, 128, 128]        7,816
├─Conv2d: 1-10                                               [1, 8192, 32, 32]         3,145,728
├─cwFModule: 1-11                                            [1, 128, 256, 256]        --
│    └─DepthwiseSeparableConv: 2-16                          [1, 256, 256, 256]        --
│    │    └─Conv2d: 3-27                                     [1, 256, 256, 256]        2,560
│    │    └─Conv2d: 3-28                                     [1, 256, 256, 256]        65,792
│    └─Conv2d: 2-17                                          [1, 256, 256, 256]        65,792
│    └─AdaptiveAvgPool2d: 2-18                               [1, 256, 1, 1]            --
│    └─Conv2d: 2-19                                          [1, 128, 1, 1]            32,896
├─Conv2d: 1-12                                               [1, 64, 256, 256]         8,192
├─ModuleList: 1-13                                           --                        (recursive)
│    └─Sequential: 2-20                                      [1, 64, 256, 256]         --
│    │    └─HAPEBlock: 3-29                                  [1, 64, 256, 256]         14,880
│    │    └─HAPEBlock: 3-30                                  [1, 64, 256, 256]         14,880
│    │    └─HAPEBlock: 3-31                                  [1, 64, 256, 256]         14,880
├─Conv2d: 1-14                                               [1, 6, 512, 512]          384
==============================================================================================================</span></span></span></code></pre><div id="https://www.notion.so/10a76526d1cc80d89314e8b7943fb64b" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">模型FloPs</strong></span></span></p></div><pre id="https://www.notion.so/10a76526d1cc80f2b32ff13a668f72d9" class="Code"><code><span class="SemanticStringArray"><span class="SemanticString"><span>==============================================================================================================
| module                           | #parameters or shape   | #flops     |
|:---------------------------------|:-----------------------|:-----------|
| model                            | 7.281M                 | 28.863G    |
==============================================================================================================</span></span></span></code></pre><div id="https://www.notion.so/4e4923ee395648349b55330f0f52d037" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">HAPE Blocks</strong></span></span></p></div><pre id="https://www.notion.so/dffc0b39684c42cfae52e87973f85f46" class="Code Code--NoWrap"><code><span class="SemanticStringArray"><span class="SemanticString"><span><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> <span class="token constant">F</span>

<span class="token keyword">class</span> <span class="token class-name">PEM</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token operator">:</span>
    def <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_channels<span class="token punctuation">)</span><span class="token operator">:</span>
        <span class="token keyword">super</span><span class="token punctuation">(</span><span class="token constant">PEM</span><span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">__init__</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>gap <span class="token operator">=</span> nn<span class="token punctuation">.</span><span class="token function">AdaptiveAvgPool2d</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>fc <span class="token operator">=</span> nn<span class="token punctuation">.</span><span class="token function">Conv2d</span><span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> in_channels<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>

    def <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token operator">:</span>
        x1 <span class="token operator">=</span> self<span class="token punctuation">.</span><span class="token function">gap</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x1 <span class="token operator">=</span> x1<span class="token punctuation">.</span><span class="token function">view</span><span class="token punctuation">(</span>x1<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token constant">A</span> <span class="token operator">=</span> <span class="token constant">F</span><span class="token punctuation">.</span><span class="token function">softmax</span><span class="token punctuation">(</span>x1<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">view</span><span class="token punctuation">(</span>x1<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> x1<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> x <span class="token operator">*</span> <span class="token constant">A</span> <span class="token operator">+</span> x
        <span class="token keyword">return</span> x

def <span class="token function">channel_shuffle</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> groups<span class="token punctuation">)</span><span class="token operator">:</span>
    batchsize<span class="token punctuation">,</span> num_channels<span class="token punctuation">,</span> height<span class="token punctuation">,</span> width <span class="token operator">=</span> x<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    channels_per_group <span class="token operator">=</span> num_channels <span class="token comment">// groups</span>

    # Reshape
    x <span class="token operator">=</span> x<span class="token punctuation">.</span><span class="token function">view</span><span class="token punctuation">(</span>batchsize<span class="token punctuation">,</span> groups<span class="token punctuation">,</span> channels_per_group<span class="token punctuation">,</span> height<span class="token punctuation">,</span> width<span class="token punctuation">)</span>

    # Transpose
    x <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token function">transpose</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">contiguous</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

    # Flatten
    x <span class="token operator">=</span> x<span class="token punctuation">.</span><span class="token function">view</span><span class="token punctuation">(</span>batchsize<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> height<span class="token punctuation">,</span> width<span class="token punctuation">)</span>

    <span class="token keyword">return</span> x
   
<span class="token keyword">class</span> <span class="token class-name">DepthwiseSeparableConv</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token operator">:</span>
    def <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> kernel_size<span class="token punctuation">,</span> padding<span class="token punctuation">,</span> dilation<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">:</span>
        <span class="token keyword">super</span><span class="token punctuation">(</span>DepthwiseSeparableConv<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">__init__</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>depthwise <span class="token operator">=</span> nn<span class="token punctuation">.</span><span class="token function">Conv2d</span><span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> in_channels<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span>kernel_size<span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span>padding<span class="token punctuation">,</span> dilation<span class="token operator">=</span>dilation<span class="token punctuation">,</span> groups<span class="token operator">=</span>in_channels<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>pointwise <span class="token operator">=</span> nn<span class="token punctuation">.</span><span class="token function">Conv2d</span><span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>

    def <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token operator">:</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span><span class="token function">depthwise</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span><span class="token function">pointwise</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> x
    
<span class="token keyword">class</span> <span class="token class-name">HAPEBlock</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token operator">:</span>
    def <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_channels<span class="token punctuation">,</span> denote<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">:</span>
        <span class="token keyword">super</span><span class="token punctuation">(</span>HAPEBlock<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">__init__</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
        com_channels <span class="token operator">=</span> in_channels <span class="token comment">// denote</span>
        self<span class="token punctuation">.</span>d <span class="token operator">=</span> denote
        self<span class="token punctuation">.</span>conv_in <span class="token operator">=</span> nn<span class="token punctuation">.</span><span class="token function">Conv2d</span><span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> com_channels<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>convs <span class="token operator">=</span> nn<span class="token punctuation">.</span><span class="token function">ModuleList</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>PEMs <span class="token operator">=</span> nn<span class="token punctuation">.</span><span class="token function">ModuleList</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
        
        # Define convolutional layers based on the denote value
        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token function">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> denote<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">:</span>
            <span class="token keyword">if</span> i<span class="token operator">%</span><span class="token number">4</span> <span class="token operator">==</span> <span class="token number">1</span><span class="token operator">:</span>
                self<span class="token punctuation">.</span>convs<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span><span class="token function">Sequential</span><span class="token punctuation">(</span>
                    nn<span class="token punctuation">.</span><span class="token function">Conv2d</span><span class="token punctuation">(</span>com_channels<span class="token punctuation">,</span> com_channels<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                    nn<span class="token punctuation">.</span><span class="token function">Conv2d</span><span class="token punctuation">(</span>com_channels<span class="token punctuation">,</span> com_channels<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                <span class="token punctuation">)</span><span class="token punctuation">)</span>
            elif i<span class="token operator">%</span><span class="token number">4</span> <span class="token operator">==</span> <span class="token number">2</span><span class="token operator">:</span>
                self<span class="token punctuation">.</span>convs<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span><span class="token function">Sequential</span><span class="token punctuation">(</span>
                    <span class="token function">DepthwiseSeparableConv</span><span class="token punctuation">(</span>com_channels<span class="token punctuation">,</span> com_channels<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                    <span class="token function">DepthwiseSeparableConv</span><span class="token punctuation">(</span>com_channels<span class="token punctuation">,</span> com_channels<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                <span class="token punctuation">)</span><span class="token punctuation">)</span>
            elif i<span class="token operator">%</span><span class="token number">4</span> <span class="token operator">==</span> <span class="token number">3</span><span class="token operator">:</span>
                self<span class="token punctuation">.</span>convs<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span><span class="token function">Sequential</span><span class="token punctuation">(</span>
                    <span class="token function">DepthwiseSeparableConv</span><span class="token punctuation">(</span>com_channels<span class="token punctuation">,</span> com_channels<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                    <span class="token function">DepthwiseSeparableConv</span><span class="token punctuation">(</span>com_channels<span class="token punctuation">,</span> com_channels<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                <span class="token punctuation">)</span><span class="token punctuation">)</span>
            elif i<span class="token operator">%</span><span class="token number">4</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token operator">:</span>
                self<span class="token punctuation">.</span>convs<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span><span class="token function">Sequential</span><span class="token punctuation">(</span>
                    <span class="token function">DepthwiseSeparableConv</span><span class="token punctuation">(</span>com_channels<span class="token punctuation">,</span> com_channels<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                    <span class="token function">DepthwiseSeparableConv</span><span class="token punctuation">(</span>com_channels<span class="token punctuation">,</span> com_channels<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">)</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                <span class="token punctuation">)</span><span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>PEMs<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span><span class="token constant">PEM</span><span class="token punctuation">(</span>in_channels<span class="token operator">=</span>com_channels<span class="token punctuation">)</span><span class="token punctuation">)</span>
        
        self<span class="token punctuation">.</span>conv_out <span class="token operator">=</span> nn<span class="token punctuation">.</span><span class="token function">Conv2d</span><span class="token punctuation">(</span>com_channels<span class="token punctuation">,</span> in_channels<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        
    def <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token operator">:</span>
        shot <span class="token operator">=</span> x
        x_in <span class="token operator">=</span> self<span class="token punctuation">.</span><span class="token function">conv_in</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        
        # Process each convolution and <span class="token constant">PEM</span>
        outputs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token function">range</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>d<span class="token punctuation">)</span><span class="token operator">:</span>
            x_conv <span class="token operator">=</span> self<span class="token punctuation">.</span>convs<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">(</span>x_in<span class="token punctuation">)</span>
            
            x_pem <span class="token operator">=</span> self<span class="token punctuation">.</span>PEMs<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">(</span>x_conv<span class="token punctuation">)</span>
            outputs<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span>x_pem<span class="token punctuation">)</span>
        
        x <span class="token operator">=</span> <span class="token function">sum</span><span class="token punctuation">(</span>outputs<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span><span class="token function">conv_out</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token operator">+</span> shot
        x <span class="token operator">=</span> nn<span class="token punctuation">.</span><span class="token function">ReLU6</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> <span class="token function">channel_shuffle</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> self<span class="token punctuation">.</span>d<span class="token punctuation">)</span>
        <span class="token keyword">return</span> x

# Example usage
<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token operator">:</span>
    input_tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token function">randn</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span>  # Example input
    model <span class="token operator">=</span> <span class="token function">HAPEBlock</span><span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span> denote<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">)</span>  # Change denote to <span class="token number">6</span>
    output <span class="token operator">=</span> <span class="token function">model</span><span class="token punctuation">(</span>input_tensor<span class="token punctuation">)</span>
    <span class="token function">print</span><span class="token punctuation">(</span>output<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
############################
torch<span class="token punctuation">.</span><span class="token function">Size</span><span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
############################</span></span></span></code></pre></article>
  <footer class="Footer">
  <div>&copy; Simon’s Blogs 2022</div>
  <div>&centerdot;</div>
  <div>Powered by <a href="https://github.com/dragonman225/notablog" target="_blank"
      rel="noopener noreferrer">Notablog</a>.
  </div>
</footer>
</body>

</html>